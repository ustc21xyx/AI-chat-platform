

# 产品需求文档 (PRD)：中文AI聊天公益平台

## 1. 项目概述

### 1.1 项目背景
随着大型语言模型（LLM）的快速发展，市面上涌现出许多优秀的AI模型。本项目旨在建立一个公益性的中文AI聊天平台，聚合多个AI提供商的服务，为用户提供一个统一、高质量、现代化的聊天界面，方便公众体验和使用不同的AI模型。

### 1.2 项目目标
*   构建一个专业、易用且响应迅速的中文AI聊天Web界面。
*   实现一个灵活的后端架构，支持接入任意数量遵循OpenAI API标准的AI提供商。
*   开发一个安全的管理后台，用于配置提供商、自动发现模型、管理模型可用性及自定义模型展示名称。

### 1.3 目标用户
*   **普通用户 (End-Users):** 希望体验和使用不同AI模型进行问答、学习、创作的用户。
*   **平台管理员 (Admins):** 负责配置AI模型源、管理平台运营和维护的人员。

## 2. 功能需求

系统主要分为三大模块：用户聊天前端、核心代理后端、系统管理后台。

### 2.1 用户聊天前端 (Frontend)

用户界面应参考ChatGPT的设计风格，注重简洁性和用户体验。

| 功能点 | 描述 | 优先级 |
| :--- | :--- | :--- |
| **界面语言与风格** | 所有界面元素、提示信息必须为简体中文。采用现代化、专业的聊天界面布局（左侧历史记录，右侧聊天区）。 | P0 |
| **模型选择器** | 用户可以通过下拉菜单或模态窗口选择AI模型。选择器应清晰展示管理员设定的**自定义名称**和描述。 | P0 |
| **实时对话 (Streaming)** | 必须支持流式输出（SSE）。AI的回复应逐字或逐句实时显示，而不是等待完整回复生成后才显示。 | P0 |
| **消息输入与控制** | 提供文本输入框，支持多行输入。提供“发送”按钮，并在生成过程中提供“停止生成”和“重新生成”按钮。 | P0 |
| **内容渲染** | 支持Markdown格式渲染，包括标题、列表、表格等。特别需要支持代码块高亮显示和一键复制功能。 | P1 |
| **对话历史记录** | 自动保存对话历史。初期使用浏览器本地存储（LocalStorage）实现。用户可以查看、继续、重命名或删除历史对话。 | P1 |
| **响应式设计** | 适配桌面端和移动端浏览器，确保在不同设备上均有良好的使用体验。 | P1 |

### 2.2 核心代理后端 (Backend Core/Proxy)

负责连接前端用户请求和后端AI提供商。

| 功能点 | 描述 | 优先级 |
| :--- | :--- | :--- |
| **API代理与路由** | 接收前端请求，根据用户选择的模型ID，查找对应的提供商配置（API Key, Base URL），并将请求转发。 | P0 |
| **OpenAI API兼容性** | 后端必须能够与任何遵循OpenAI API规范（特别是 `/v1/chat/completions`）的AI提供商进行通信，包括流式传输（`stream: true`）。 | P0 |
| **流式响应处理** | 高效处理来自提供商的SSE流式响应，并实时转发回前端，确保低延迟。 | P0 |
| **模型配置服务** | 提供API接口，向前端暴露管理员已启用的模型列表及其自定义元数据。 | P0 |
| **错误处理** | 统一处理来自AI提供商的错误（如速率限制、API Key无效、超时），并返回标准化的中文错误信息给前端。 | P1 |

### 2.3 系统管理后台 (Admin Panel)

仅供管理员访问，与普通用户界面隔离。

| 功能点 | 描述 | 优先级 |
| :--- | :--- | :--- |
| **安全认证** | 独立的管理员登录机制。必须安全，防止未授权访问。 | P0 |
| **AI提供商管理** | 管理AI模型提供商（Provider）。 | P0 |
| ├─ 添加/编辑提供商 | 配置项包括：提供商名称（内部标识）、API Endpoint URL（如 `https://api.provider.com/v1`）、API Key。 | P0 |
| ├─ API Key安全存储 | API Key 必须在数据库中加密存储，且不能在管理界面明文显示。 | P0 |
| ├─ 连接测试 | 提供按钮测试Endpoint和API Key是否有效。 | P1 |
| **模型发现与同步** | 自动从配置好的提供商拉取模型列表。 | P0 |
| ├─ 自动模型发现 | 管理员手动触发“同步模型”操作。系统调用提供商的 `/v1/models` 接口，获取模型列表及其ID，并更新到数据库。 | P0 |
| **模型管理系统** | 管理从提供商同步过来的模型，控制其在前端的显示。 | P0 |
| ├─ 模型列表 | 展示所有已发现的模型，包括原始模型ID、所属提供商、状态。 | P0 |
| ├─ 启用/禁用模型 | 管理员选择性地启用或禁用模型。只有启用的模型才会出现在前端用户界面。 | P0 |
| ├─ 自定义元数据 | 管理员可以设置**自定义显示名称**（用户看到的名称）、模型描述和显示排序。 | P0 |

## 3. 非功能需求

### 3.1 性能与可扩展性
*   **低延迟**：前端页面加载迅速，API代理层的延迟应尽可能低，保证流式传输的流畅性。
*   **可扩展性**：架构设计应允许未来轻松添加更多的AI提供商和支持水平扩展。

### 3.2 安全性
*   **数据加密**：全程使用HTTPS传输。提供商的API Key必须在数据库中加密存储。
*   **权限控制**：严格控制对后台管理面板的访问，防范暴力破解。
*   **数据隐私**：遵守相关数据保护法规。应明确告知用户对话数据的使用政策。

### 3.3 兼容性
*   **API兼容性**：严格遵循OpenAI API规范，确保与多数提供商的兼容性。
*   **浏览器兼容性**：支持主流现代浏览器（Chrome, Firefox, Safari, Edge）。

## 4. 技术栈选型建议

基于现代化、高性能和开发效率的考虑，建议采用以下技术栈：

*   **前端:**
    *   **框架:** Next.js (React) - 社区成熟，生态丰富，有大量高质量的开源聊天UI项目可供参考（如 LobeChat, Open WebUI）。
    *   **UI库:** Tailwind CSS 配合 Shadcn/UI - 实现快速、高质量的界面开发和定制。
    *   **语言:** TypeScript。
*   **后端:**
    *   **方案A (轻量级/初期):** 使用 Next.js 的 API Routes。前后端在同一个项目中，适合快速启动。
    *   **方案B (高扩展性/推荐):** Python (FastAPI)。在AI领域生态丰富，对异步处理和流式响应支持优秀，性能高。
*   **数据库:**
    *   PostgreSQL 或 MySQL - 存储结构化数据（提供商配置、模型元数据、管理员账户）。

## 5. 实施计划（分阶段）

建议分阶段实施，以快速交付可用产品：

### 阶段一：最小可行产品 (MVP)
*   M1.1: 前后端项目初始化与数据库设计。
*   M1.2: 实现基础的聊天界面（支持流式传输、Markdown渲染）。
*   M1.3: 实现后端API代理核心逻辑，支持配置单一AI提供商。
*   M1.4: 实现简单的管理员认证。

### 阶段二：完善管理功能与多提供商支持
*   M2.1: 开发完整的后台管理面板UI。
*   M2.2: 实现AI提供商管理功能。
*   M2.3: 实现模型自动发现 (`/v1/models`) 和同步功能。
*   M2.4: 实现模型管理功能（自定义名称、启用/禁用、排序）。
*   M2.5: 前后端联调，实现基于管理配置的多模型切换。

### 阶段三：优化与上线
*   M3.1: 优化前端用户体验（对话历史本地存储、UI细节打磨）。
*   M3.2: 安全性加固和性能调优。
*   M3.3: 部署与上线。

